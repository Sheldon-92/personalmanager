"""AIå¯è°ƒç”¨çš„ç”¨æˆ·åå¥½å­¦ä¹ å·¥å…·å‡½æ•° - é‡æ„è‡ªpreferenceså‘½ä»¤"""

from typing import Tuple, Optional, Dict, Any
import structlog
from datetime import datetime

from pm.core.config import PMConfig
from pm.agents.gtd_agent import GTDAgent

logger = structlog.get_logger()


def get_preference_learning_stats(
    config: Optional[PMConfig] = None
) -> Tuple[bool, str, Optional[Dict[str, Any]]]:
    """è·å–ç”¨æˆ·åå¥½å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯çš„AIå¯è°ƒç”¨å·¥å…·å‡½æ•°
    
    æä¾›åå¥½å­¦ä¹ å¼•æ“çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - å­¦ä¹ çŠ¶æ€å’Œè¿›å±•
    - ç†è®ºæ¡†æ¶åå¥½æƒé‡
    - æƒ…å¢ƒä½¿ç”¨åå¥½
    - å­¦ä¹ å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦
    - ä¸ªæ€§åŒ–å»ºè®®
    
    Args:
        config: å¯é€‰çš„PMConfigå®ä¾‹
        
    Returns:
        Tuple[bool, str, Optional[Dict[str, Any]]]: (æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, åå¥½ç»Ÿè®¡æ•°æ®)
    """
    
    try:
        # åˆå§‹åŒ–é…ç½®
        if config is None:
            config = PMConfig()
        
        if not config.is_initialized():
            return False, "ç³»ç»Ÿæœªåˆå§‹åŒ–ã€‚è¯·å…ˆè¿è¡Œ pm setup è¿›è¡Œè®¾ç½®ã€‚", None
        
        # åˆ›å»ºGTD Agent
        agent = GTDAgent(config)
        
        # è·å–åå¥½å­¦ä¹ ç»Ÿè®¡
        stats = agent.get_preference_learning_stats()
        
        # ä¸°å¯Œç»Ÿè®¡æ•°æ®
        enhanced_stats = _enhance_preference_stats(stats)
        
        logger.info("Preference learning stats retrieved successfully",
                   total_choices=stats['total_choices'],
                   accuracy=stats['recent_accuracy'])
        
        return True, "åå¥½å­¦ä¹ ç»Ÿè®¡è·å–æˆåŠŸ", enhanced_stats
        
    except Exception as e:
        logger.error("Failed to get preference learning stats", error=str(e))
        return False, f"è·å–åå¥½å­¦ä¹ ç»Ÿè®¡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", None


def analyze_framework_preferences(
    config: Optional[PMConfig] = None
) -> Tuple[bool, str, Optional[Dict[str, Any]]]:
    """åˆ†æç”¨æˆ·çš„ç†è®ºæ¡†æ¶åå¥½
    
    Args:
        config: å¯é€‰çš„PMConfigå®ä¾‹
        
    Returns:
        Tuple[bool, str, Optional[Dict[str, Any]]]: (æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, æ¡†æ¶åå¥½åˆ†æ)
    """
    
    try:
        if config is None:
            config = PMConfig()
        
        if not config.is_initialized():
            return False, "ç³»ç»Ÿæœªåˆå§‹åŒ–", None
        
        agent = GTDAgent(config)
        stats = agent.get_preference_learning_stats()
        
        if not stats['framework_preferences']:
            return True, "æš‚æ— æ¡†æ¶åå¥½æ•°æ®", {
                'has_data': False,
                'framework_preferences': {},
                'recommendations': ["ç»§ç»­ä½¿ç”¨æ¨èåŠŸèƒ½ä»¥æ”¶é›†åå¥½æ•°æ®"]
            }
        
        # åˆ†ææ¡†æ¶åå¥½
        framework_analysis = _analyze_framework_preferences(stats['framework_preferences'])
        
        return True, "æ¡†æ¶åå¥½åˆ†æå®Œæˆ", framework_analysis
        
    except Exception as e:
        logger.error("Failed to analyze framework preferences", error=str(e))
        return False, f"åˆ†ææ¡†æ¶åå¥½æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", None


def analyze_context_preferences(
    config: Optional[PMConfig] = None
) -> Tuple[bool, str, Optional[Dict[str, Any]]]:
    """åˆ†æç”¨æˆ·çš„æƒ…å¢ƒä½¿ç”¨åå¥½
    
    Args:
        config: å¯é€‰çš„PMConfigå®ä¾‹
        
    Returns:
        Tuple[bool, str, Optional[Dict[str, Any]]]: (æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, æƒ…å¢ƒåå¥½åˆ†æ)
    """
    
    try:
        if config is None:
            config = PMConfig()
        
        if not config.is_initialized():
            return False, "ç³»ç»Ÿæœªåˆå§‹åŒ–", None
        
        agent = GTDAgent(config)
        stats = agent.get_preference_learning_stats()
        
        if not stats['context_preferences']:
            return True, "æš‚æ— æƒ…å¢ƒåå¥½æ•°æ®", {
                'has_data': False,
                'context_preferences': {},
                'recommendations': ["åœ¨ä¸åŒæƒ…å¢ƒä¸‹ä½¿ç”¨ä»»åŠ¡ä»¥æ”¶é›†åå¥½æ•°æ®"]
            }
        
        # åˆ†ææƒ…å¢ƒåå¥½
        context_analysis = _analyze_context_preferences(stats['context_preferences'])
        
        return True, "æƒ…å¢ƒåå¥½åˆ†æå®Œæˆ", context_analysis
        
    except Exception as e:
        logger.error("Failed to analyze context preferences", error=str(e))
        return False, f"åˆ†ææƒ…å¢ƒåå¥½æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", None


def get_learning_recommendations(
    config: Optional[PMConfig] = None
) -> Tuple[bool, str, Optional[Dict[str, Any]]]:
    """è·å–ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®
    
    Args:
        config: å¯é€‰çš„PMConfigå®ä¾‹
        
    Returns:
        Tuple[bool, str, Optional[Dict[str, Any]]]: (æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, å­¦ä¹ å»ºè®®)
    """
    
    try:
        if config is None:
            config = PMConfig()
        
        if not config.is_initialized():
            return False, "ç³»ç»Ÿæœªåˆå§‹åŒ–", None
        
        agent = GTDAgent(config)
        stats = agent.get_preference_learning_stats()
        
        # ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        recommendations = _generate_learning_recommendations(stats)
        
        return True, "å­¦ä¹ å»ºè®®ç”ŸæˆæˆåŠŸ", recommendations
        
    except Exception as e:
        logger.error("Failed to get learning recommendations", error=str(e))
        return False, f"ç”Ÿæˆå­¦ä¹ å»ºè®®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", None


def _enhance_preference_stats(stats: Dict[str, Any]) -> Dict[str, Any]:
    """ä¸°å¯Œåå¥½ç»Ÿè®¡æ•°æ®"""
    
    enhanced = stats.copy()
    
    # æ·»åŠ æ¡†æ¶åå¥½åˆ†æ
    if stats['framework_preferences']:
        enhanced['framework_analysis'] = _analyze_framework_preferences(stats['framework_preferences'])
    else:
        enhanced['framework_analysis'] = {'has_data': False}
    
    # æ·»åŠ æƒ…å¢ƒåå¥½åˆ†æ
    if stats['context_preferences']:
        enhanced['context_analysis'] = _analyze_context_preferences(stats['context_preferences'])
    else:
        enhanced['context_analysis'] = {'has_data': False}
    
    # æ·»åŠ å­¦ä¹ å»ºè®®
    enhanced['learning_recommendations'] = _generate_learning_recommendations(stats)
    
    # æ·»åŠ çŠ¶æ€è¯„ä¼°
    enhanced['status_assessment'] = _assess_learning_status_detailed(stats)
    
    return enhanced


def _analyze_framework_preferences(framework_prefs: Dict[str, float]) -> Dict[str, Any]:
    """åˆ†æç†è®ºæ¡†æ¶åå¥½"""
    
    framework_names = {
        'okr_wig': 'ã€Šè¡¡é‡ä¸€åˆ‡ã€‹',
        '4dx': 'ã€Šé«˜æ•ˆæ‰§è¡Œ4åŸåˆ™ã€‹',
        'full_engagement': 'ã€Šå…¨åŠ›ä»¥èµ´ã€‹',
        'atomic_habits': 'ã€ŠåŸå­ä¹ æƒ¯ã€‹',
        'gtd': 'ã€Šæå®šã€‹',
        'essentialism': 'ã€Šç²¾è¦ä¸»ä¹‰ã€‹'
    }
    
    # æŒ‰åå¥½å¼ºåº¦æ’åº
    sorted_prefs = sorted(framework_prefs.items(), key=lambda x: x[1], reverse=True)
    
    analysis = {
        'has_data': True,
        'top_framework': {
            'key': sorted_prefs[0][0],
            'name': framework_names.get(sorted_prefs[0][0], sorted_prefs[0][0]),
            'weight': sorted_prefs[0][1]
        },
        'preferences_by_strength': []
    }
    
    for framework_key, weight in sorted_prefs:
        framework_name = framework_names.get(framework_key, framework_key)
        
        # åå¥½å¼ºåº¦è¯„ä¼°
        if weight > 0.3:
            strength = "å¼ºåå¥½"
            strength_level = 4
            icon = "ğŸ”¥"
        elif weight > 0.2:
            strength = "ä¸­åå¥½"
            strength_level = 3
            icon = "âš¡"
        elif weight > 0.1:
            strength = "è½»åå¥½"
            strength_level = 2
            icon = "ğŸ’¡"
        else:
            strength = "ä½åå¥½"
            strength_level = 1
            icon = "â–"
        
        analysis['preferences_by_strength'].append({
            'key': framework_key,
            'name': framework_name,
            'weight': weight,
            'strength': strength,
            'strength_level': strength_level,
            'icon': icon
        })
    
    return analysis


def _analyze_context_preferences(context_prefs: Dict[str, float]) -> Dict[str, Any]:
    """åˆ†ææƒ…å¢ƒä½¿ç”¨åå¥½"""
    
    # æŒ‰ä½¿ç”¨é¢‘ç‡æ’åº
    sorted_contexts = sorted(context_prefs.items(), key=lambda x: x[1], reverse=True)
    
    analysis = {
        'has_data': True,
        'most_used_context': {
            'key': sorted_contexts[0][0],
            'frequency': sorted_contexts[0][1]
        },
        'contexts_by_frequency': []
    }
    
    for context_key, frequency in sorted_contexts:
        if frequency > 0.4:
            level = "é«˜é¢‘ä½¿ç”¨"
            level_rank = 3
            icon = "ğŸŒŸ"
        elif frequency > 0.2:
            level = "å¸¸ç”¨"
            level_rank = 2
            icon = "â­"
        else:
            level = "å¶ç”¨"
            level_rank = 1
            icon = "ğŸ’«"
        
        analysis['contexts_by_frequency'].append({
            'key': context_key,
            'frequency': frequency,
            'level': level,
            'level_rank': level_rank,
            'icon': icon
        })
    
    return analysis


def _generate_learning_recommendations(stats: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®"""
    
    total_choices = stats['total_choices']
    recent_accuracy = stats['recent_accuracy']
    
    recommendations = {
        'primary_message': "",
        'suggestions': [],
        'next_actions': []
    }
    
    if total_choices < 5:
        recommendations['primary_message'] = "å¼€å§‹ä¸ªæ€§åŒ–å­¦ä¹ ä¹‹æ—…ï¼"
        recommendations['suggestions'] = [
            "ç³»ç»Ÿæ­£åœ¨å­¦ä¹ æ‚¨çš„åå¥½æ¨¡å¼",
            "éšç€æ‚¨ä½¿ç”¨æ¨èåŠŸèƒ½ï¼ŒPersonalManagerå°†è¶Šæ¥è¶Šäº†è§£æ‚¨çš„å·¥ä½œä¹ æƒ¯"
        ]
        recommendations['next_actions'] = [
            "ä½¿ç”¨ pm recommend è·å–æ™ºèƒ½æ¨è",
            "é€‰æ‹©æ‰§è¡Œæ¨èçš„ä»»åŠ¡",
            "ç³»ç»Ÿå°†è‡ªåŠ¨å­¦ä¹ æ‚¨çš„åå¥½"
        ]
    elif recent_accuracy > 0.7:
        recommendations['primary_message'] = "å­¦ä¹ æ•ˆæœä¼˜ç§€ï¼"
        recommendations['suggestions'] = [
            f"æ‚¨çš„æ¨èå‡†ç¡®ç‡è¾¾åˆ° {recent_accuracy:.1%}",
            "ç³»ç»Ÿå·²ç»å¾ˆå¥½åœ°ç†è§£äº†æ‚¨çš„å·¥ä½œåå¥½"
        ]
        recommendations['next_actions'] = [
            "ç»§ç»­ä½¿ç”¨æ¨èåŠŸèƒ½ï¼Œäº«å—ä¸ªæ€§åŒ–çš„æ™ºèƒ½å»ºè®®ï¼"
        ]
    else:
        recommendations['primary_message'] = "æŒç»­å­¦ä¹ ä¸­..."
        recommendations['suggestions'] = [
            f"å½“å‰å‡†ç¡®ç‡: {recent_accuracy:.1%}",
            "ç³»ç»Ÿæ­£åœ¨ä¸æ–­ä¼˜åŒ–å¯¹æ‚¨åå¥½çš„ç†è§£"
        ]
        recommendations['next_actions'] = [
            "è¯·ç»§ç»­ä½¿ç”¨æ¨èåŠŸèƒ½ï¼Œæä¾›æ›´å¤šå­¦ä¹ æ ·æœ¬"
        ]
    
    return recommendations


def _assess_learning_status_detailed(stats: Dict[str, Any]) -> Dict[str, Any]:
    """è¯¦ç»†è¯„ä¼°å­¦ä¹ çŠ¶æ€"""
    
    total_choices = stats['total_choices']
    recent_accuracy = stats['recent_accuracy']
    confidence_score = stats['confidence_score']
    learning_status = stats['learning_status']
    
    status_details = {
        'status': learning_status,
        'progress_percentage': min(100, (total_choices / 20) * 100),
        'accuracy_trend': "ä¸Šå‡" if recent_accuracy > 0.6 else "å¹³ç¨³" if recent_accuracy > 0.4 else "å¾…æå‡",
        'confidence_level': "é«˜" if confidence_score > 0.7 else "ä¸­" if confidence_score > 0.4 else "ä½",
        'data_sufficiency': "å……è¶³" if total_choices >= 20 else "é€‚ä¸­" if total_choices >= 5 else "ä¸è¶³"
    }
    
    return status_details